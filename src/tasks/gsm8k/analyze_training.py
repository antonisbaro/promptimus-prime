"""
GSM8K Training Evolution Analysis Script.

This module parses the final checkpoint file generated by a training run
to analyze the step-by-step evolution of the optimization process.

It extracts the validation score and the state of the prompts (instruction, demos)
at each training step, providing a comprehensive history of the learning trajectory.

The script generates two key artifacts for analysis:
1.  A detailed CSV report (`training_evolution.csv`) logging the performance
    and prompt content at every step.
2.  A plot (`score_evolution.png`) visualizing the validation score over time,
    compared against the initial baseline score.

This allows for both quantitative and qualitative analysis of how the optimizer
adapts the prompts throughout the training process.

Usage:
    Run as a module from the project root after a training session is complete:
    $ python -m src.tasks.gsm8k.analyze_training
"""

import os
import glob
import json
import pandas as pd
import matplotlib.pyplot as plt

from src.tasks.gsm8k.config import CKPT_DIR, OUTPUT_DIR

def find_latest_run_file(ckpt_dir: str) -> str:
    """Finds the most recently modified checkpoint file in the directory."""
    list_of_files = glob.glob(os.path.join(ckpt_dir, "*.json"))
    if not list_of_files:
        return None
    latest_file = max(list_of_files, key=os.path.getctime)
    return latest_file

def analyze():
    """
    Analyzes the results of a completed training run by parsing the final
    checkpoint file, which contains the full history of all steps.
    """
    print("üìà Analyzing training evolution from the latest checkpoint...")
    
    # 1. Find the final checkpoint file
    # We don't need to know the exact name, just find the latest one.
    ckpt_file = find_latest_run_file(CKPT_DIR)
    if not ckpt_file:
        print(f"‚ùå No checkpoint files found in '{CKPT_DIR}'. Please run train.py first.")
        return

    print(f"üìÇ Loading data from: {os.path.basename(ckpt_file)}")

    # 2. Load the JSON data
    with open(ckpt_file, 'r') as f:
        run_data = json.load(f)

    # The history is stored in the 'step_results' key
    step_results = run_data.get("step_results", [])
    if not step_results:
        print("Checkpoint file does not contain any step results.")
        return

    # 3. Extract the data we need for each step
    evolution_data = []
    for result in step_results:
        step = result.get("step")
        val_score = result.get("val_score")
        
        # Find the 'instruction' and 'demos' prompts from the list
        prompts = result.get("prompt", [])
        instruction = next((p['data'] for p in prompts if p.get('name') == 'instruction'), "N/A")
        demos = next((p['data'] for p in prompts if p.get('name') == 'demos'), "N/A")
        output_format = next((p['data'] for p in prompts if p.get('name') == 'output_format'), "N/A")

        evolution_data.append({
            "step": step,
            "validation_score": val_score,
            "instruction": instruction,
            "demos": demos,
            "output_format": output_format
        })

    # 4. Create and save the DataFrame
    df_evo = pd.DataFrame(evolution_data)
    
    output_csv = os.path.join(OUTPUT_DIR, "training_evolution.csv")
    df_evo.to_csv(output_csv, index=False)
    print(f"\nüíæ Saved detailed training evolution to: {output_csv}")

    # 5. Create and save the plot
    # We will plot all steps, including step 0, to show the full evolution.
    if not df_evo.empty:
        steps = df_evo["step"]
        scores = df_evo["validation_score"]
        
        plt.figure(figsize=(12, 7))
        plt.plot(steps, scores, marker='o', linestyle='-', label="Validation Score per Step")
        
        # Add a horizontal dashed line representing the initial (step 0) score.
        # This makes it easy to see when the optimization surpasses the baseline.
        initial_score = df_evo["validation_score"][0]
        plt.axhline(y=initial_score, color='r', linestyle='--', label=f'Initial Score (Step 0): {initial_score:.2f}')
        
        plt.title("Validation Score Evolution During Optimization")
        plt.xlabel("Training Step")
        plt.ylabel("Validation Accuracy")
        plt.grid(True)
        plt.xticks(df_evo["step"].unique()) # Ensure integer ticks for steps
        plt.legend()
        
        plot_path = os.path.join(OUTPUT_DIR, "score_evolution.png")
        plt.savefig(plot_path)
        print(f"üìä Saved score evolution plot to: {plot_path}")

if __name__ == "__main__":
    analyze()